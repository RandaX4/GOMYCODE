{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2eae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') # You can either use your drive or work directly on colab with temporary import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a696e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Me Please\n",
    "!pip -q install pydot_ng\n",
    "!pip -q install graphviz\n",
    "!apt install graphviz > /dev/null\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "# try:\n",
    "#   tf.enable_eager_execution()\n",
    "#   print('Running in Eager mode.')\n",
    "# except ValueError:\n",
    "#   print('Already running in Eager mode')\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "from keras.layers import Input, Lambda, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.inception_v3 import inception_v3\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Feel free to import more packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Load pickled data\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "# If you have a folder in your Drive named traffic-signs-data you do so, else change directory\n",
    "\n",
    "training_file = '/content/gdrive/My Drive/traffic-signs-data/train.p'\n",
    "validation_file= '/content/gdrive/My Drive/traffic-signs-data/valid.p'\n",
    "testing_file = '/content/gdrive/My Drive/traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete None with your code\n",
    "#-------------------------------------------------------------------------\n",
    "signs = []\n",
    "signnames = pd.read_csv('/content/gdrive/My Drive/traffic-signs-data/signnames.csv', delimiter=',', header=0)\n",
    "for row in range(signnames.shape[0]):\n",
    "     signs.append(signnames.iloc[row, 1])    \n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d355207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please complete None with your code\n",
    "#-------------------------------------------------------------------------\n",
    "#  Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# Number of test examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "#  What's the shape of a traffic sign image?\n",
    "image_shape = X_test[0].shape\n",
    "\n",
    "#  How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Number of valid examples =\", n_validation)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2fdb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n this part you should One-hot encode all Y-s vectors using\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encodedtrain_Y = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "Ytrain = np_utils.to_categorical(encodedtrain_Y)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_valid)\n",
    "encodedvalid_Y = encoder.transform(y_valid)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "Yvalid = np_utils.to_categorical(encodedvalid_Y)\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encodedtest_Y = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "Ytest = np_utils.to_categorical(encodedtest_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "def show_images(X,Y,r,c):\n",
    "  fig, axs = plt.subplots(r,c, figsize=(15, 6))\n",
    "  fig.subplots_adjust(hspace = .2, wspace=.001)\n",
    "  axs = axs.ravel()\n",
    "  for i in (X*Y): # if rows = 2 and columns = 5 i should take 10 values\n",
    "      index = random.randint(0, len(X))\n",
    "      image = X[index]\n",
    "      axs[i].axis('off')\n",
    "      axs[i].imshow(image)\n",
    "      axs[i].set_title(Y[index])\n",
    "  plt.show()    \n",
    "\n",
    "# show image of 10 random data points\n",
    "rows = 2\n",
    "columns = 5\n",
    "show_images (rows,columns,r,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de10576",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "item, count = np.unique(y_train, return_counts=True)\n",
    "#names is a list of traffic signs, Remember that we already have a list : signs\n",
    "names = signs \n",
    "y_pos = np.arange(len(names))\n",
    "plt.bar(item, count, alpha=0.6, color = (0.3,0.9,0.4,0.6) )\n",
    "\n",
    "plt.xticks(y_pos, names, fontsize=15, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "item, count = np.unique(y_test, return_counts=True)\n",
    "item1, count1 = np.unique(y_valid, return_counts=True)\n",
    "\n",
    "names = signs\n",
    "names1 = signs\n",
    "\n",
    "y_pos = np.arange(len(names))\n",
    "plt.bar(item, count, alpha=0.6, color = (0.3,0.5,0.4,0.2), label=\"Validation Data\" )\n",
    "\n",
    "plt.bar(item1, count1, alpha=0.6, color = (0.9,0.1,0.3,0.2), label=\"Train Data\" )\n",
    "\n",
    "plt.xticks(y_pos, names, fontsize=15, rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray scale\n",
    "X_test_gry = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "X_train_gry = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_valid_gry = np.sum(X_valid/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b31a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization Here \n",
    "X_test_gry = X_test_gry/255.\n",
    "X_train_gry = X_train_gry/255.\n",
    "X_valid_gry = X_valid_gry/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle your data here \n",
    "X_test_gry,X_train_gry,X_valid_gry=shffle(X_test_gry,X_train_gry,X_valid_gry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9edd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def random_translate(img):\n",
    "    rows,cols,_ = img.shape\n",
    "    \n",
    "    # allow translation up to px pixels in x and y directions\n",
    "    px = 2\n",
    "    dx,dy = np.random.randint(-px,px,2)\n",
    "\n",
    "    M = np.float32([[1,0,dx],[0,1,dy]])\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    dst = dst[:,:,np.newaxis]\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4feae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scaling(img):   \n",
    "    rows,cols,_ = img.shape\n",
    "\n",
    "    # transform limits\n",
    "    px = np.random.randint(-2,2)\n",
    "\n",
    "    # ending locations\n",
    "    pts1 = np.float32([[px,px],[rows-px,px],[px,cols-px],[rows-px,cols-px]])\n",
    "\n",
    "    # starting locations (4 corners)\n",
    "    pts2 = np.float32([[0,0],[rows,0],[0,cols],[rows,cols]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "    dst = cv2.warpPerspective(img,M,(rows,cols))\n",
    "    \n",
    "    dst = dst[:,:,np.newaxis]\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec384b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_warp(img):\n",
    "    \n",
    "    rows,cols,_ = img.shape\n",
    "\n",
    "    # random scaling coefficients\n",
    "    rndx = np.random.rand(3) - 0.5\n",
    "    rndx *= cols * 0.06   # this coefficient determines the degree of warping\n",
    "    rndy = np.random.rand(3) - 0.5\n",
    "    rndy *= rows * 0.06\n",
    "\n",
    "    # 3 starting points for transform, 1/4 way from edges\n",
    "    x1 = cols/4\n",
    "    x2 = 3*cols/4\n",
    "    y1 = rows/4\n",
    "    y2 = 3*rows/4\n",
    "\n",
    "    pts1 = np.float32([[y1,x1],\n",
    "                       [y2,x1],\n",
    "                       [y1,x2]])\n",
    "    pts2 = np.float32([[y1+rndy[0],x1+rndx[0]],\n",
    "                       [y2+rndy[1],x1+rndx[1]],\n",
    "                       [y1+rndy[2],x2+rndx[2]]])\n",
    "\n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    \n",
    "    dst = dst[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5ecfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_brightness(img):\n",
    "    shifted = img + 1.0   # shift to (0,2) range\n",
    "    img_max_value = max(shifted.flatten())\n",
    "    max_coef = 2.0/img_max_value\n",
    "    min_coef = max_coef - 0.1\n",
    "    coef = np.random.uniform(min_coef, max_coef)\n",
    "    dst = shifted * coef - 1.0\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if u do have a file that contains new_train data RUN ME\n",
    "with open(\"/content/gdrive/My Drive/traffic-signs-data/new_train.p\",\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "new_X_train,y_train = data[\"images\"],data[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa25326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data  \n",
    "# CODE\n",
    "new_X_train,y_train=shffle(new_X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figures_no_labels(figures, nrows = 1, ncols=1):\n",
    "    fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n",
    "    axs = axs.ravel()\n",
    "    for index, title in zip(range(len(figures)), figures):\n",
    "        axs[index].imshow(figures[title], plt.gray())\n",
    "        axs[index].set_axis_off()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "for class_n in (n_classes): # you should range for all classes \n",
    "  figures = {}\n",
    "\n",
    "  class_indices = list (np.where(y_train == class_n)[0])\n",
    "  \n",
    "  for i in range(8):\n",
    "    \n",
    "        figures[i] = new_X_train[class_indices[-i]].squeeze()\n",
    "      \n",
    "  plot_figures_no_labels(figures, 1, 8)\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae42dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [32, 32]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "image_input = Input(shape=(32, 32, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9db1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to use as many code cells as needed.\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=image_input) \n",
    "#we will include weights learned with imagenet dataset\n",
    "output = vgg.layers[-1].output\n",
    "output = Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "# we can chose which layer to train \n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "# all layers are not trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf69d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your model\n",
    "# Use pretrained model \n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "history = model.fit(new_X_train, y_train, \n",
    "                    epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid, Yvalid))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Ytest, batch_size=batch_size)\n",
    "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "\n",
    "plt.plot(Yvalid, label='Validation accuracy', color = palette(2))\n",
    "plt.plot(new_X_train, label='Train accuracy', color = palette(1))\n",
    "plt.title(\"Training Performance\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted_classes = Ytrain\n",
    "y_true = Ytest\n",
    "\n",
    "cm = confusion_matrix(y_true, predicted_classes)\n",
    "plt.figure(figsize = (25, 25))\n",
    "sns.heatmap(cm, annot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
